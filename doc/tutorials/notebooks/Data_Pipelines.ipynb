{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73403c5e-5d90-47a9-9e34-3e58570b0d98",
   "metadata": {},
   "source": [
    "# Data Module\n",
    "The data module helps you build complex data pipeline simply. Simply means that the code is readable and easily maintainable. This is due to the modularity of the data pipeline built with this module.\n",
    "\n",
    "## Overview\n",
    "The data pipeline builtd with this module can be built like a pipeline in the shell console.  They are composed of multiple sub-scripts that are agglomerated (piped) together with the pipe ```|``` operator.  This way, the sub-scripts can be reusable for multiple data pipes, and helps you build new data pipes quicker by composition of existing code.\n",
    "\n",
    "## Anatomy of a data pipeline\n",
    "The root class of the data pipelines is ```DataPipe```.  This class is a recursive and composable class.  This means that a single small script that does an elementary task is a ```DataPipe```, and an agglomeration (composition) of multiple elementary scripts is also a ```DataPipe```.  As it might be clear by now, a data pipeline is built by composition of multiple elementary pipes.  These elementary pipes are split into four categories: ```Fetch```, ```Process```, ```Collate```, ```Cache```. ```Fetch``` pipes fetch data from an external source.  It can be from the internet, from a database, from a file, etc.  ```Process``` pipes will transform the data from the upstream pipe.  It can be to change the datastructure, to impute nans, to filter the data, etc. ```Collate``` pipes are use to merge two branches of a pipeline.  For example, let's say you have a pipeline that fetch chart data from one data source, and another pipeline that fetch fundamental data formated as reports.  Each raw data needs to be processed differently, so they have their own subpipes.  However, they need to be agglomerated at the end to have a single dataset.  This is where a Collate pipe would comes in handy: it could align the two series together to merge the output of the two subpipes into one pipe.  Finally, the ```Cache``` pipe can cache the output of a data pipeline and prevent the wrapped pipeline section to run only when cache has been revalidated or expired.  Otherwise, it will return the cached data.  The default cache pipe supports multiple way of revalidating the cache."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cba1292-8945-4d8b-8e47-61babdedb05d",
   "metadata": {},
   "source": [
    "## Basic Example\n",
    "The following example will show how to build a simple pipe that can fetch chart data based on a ticker and the yfinance api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c89fd877-ad65-44b0-ac2e-71182f554c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "from backtest.data import FetchCharts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b6596-c843-4a4e-b7f2-f700f7fc05f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
